Training Set:{'ottawashooting-all-rnr-threads.txt', 'prince-toronto-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 141.41098022460938
Iteration 2 Loss: 136.16403198242188
Iteration 3 Loss: 138.60276794433594
Iteration 4 Loss: 135.75637817382812
Iteration 5 Loss: 133.80416870117188
Iteration 6 Loss: 139.32070922851562
Iteration 7 Loss: 138.27133178710938
Iteration 8 Loss: 138.48330688476562
Iteration 9 Loss: 138.1405487060547
Iteration 10 Loss: 136.70492553710938
Iteration 11 Loss: 136.2373504638672
Iteration 12 Loss: 131.8016357421875
Iteration 13 Loss: 131.9076385498047
Iteration 14 Loss: 131.54888916015625
Iteration 15 Loss: 131.4899444580078
Iteration 16 Loss: 132.84701538085938
Iteration 17 Loss: 132.54568481445312
Iteration 18 Loss: 128.87608337402344
Iteration 19 Loss: 134.10353088378906
Iteration 20 Loss: 132.59637451171875
Iteration 21 Loss: 127.31414031982422
Iteration 22 Loss: 128.95420837402344
Iteration 23 Loss: 129.57473754882812
Iteration 24 Loss: 127.28150177001953
Iteration 25 Loss: 128.8932342529297
Iteration 26 Loss: 124.87996673583984
Iteration 27 Loss: 126.65762329101562
Iteration 28 Loss: 129.6868896484375
Iteration 29 Loss: 129.22857666015625
Iteration 30 Loss: 132.64601135253906
Iteration 31 Loss: 132.57119750976562
Iteration 32 Loss: 133.6045684814453
Iteration 33 Loss: 142.33242797851562
Iteration 34 Loss: 137.63816833496094
Iteration 35 Loss: 131.54042053222656
Iteration 36 Loss: 129.7718963623047
Iteration 37 Loss: 132.89443969726562
Iteration 38 Loss: 128.13624572753906
Iteration 39 Loss: 127.69385528564453
Iteration 40 Loss: 128.09158325195312
Iteration 41 Loss: 128.30458068847656
Iteration 42 Loss: 130.08261108398438
Iteration 43 Loss: 125.86683654785156
Iteration 44 Loss: 130.90969848632812
Iteration 45 Loss: 125.91943359375
Iteration 46 Loss: 126.16106414794922
Iteration 47 Loss: 126.29178619384766
Iteration 48 Loss: 126.48597717285156
Iteration 49 Loss: 125.69576263427734
Iteration 50 Loss: 122.42814636230469
Iteration 51 Loss: 131.36871337890625
Iteration 52 Loss: 128.0941619873047
Iteration 53 Loss: 126.06907653808594
Iteration 54 Loss: 126.59600067138672
Iteration 55 Loss: 121.72441864013672
Iteration 56 Loss: 126.44481658935547
Iteration 57 Loss: 127.80241394042969
Iteration 58 Loss: 125.48133850097656
Iteration 59 Loss: 133.40399169921875
Iteration 60 Loss: 130.9967803955078
Iteration 61 Loss: 128.7064971923828
Iteration 62 Loss: 133.77993774414062
Iteration 63 Loss: 133.32467651367188
Iteration 64 Loss: 127.98744201660156
Iteration 65 Loss: 125.80642700195312
Iteration 66 Loss: 129.07681274414062
Iteration 67 Loss: 126.26275634765625
Iteration 68 Loss: 124.6356430053711
Iteration 69 Loss: 126.1709213256836
Iteration 70 Loss: 125.64424896240234
Iteration 71 Loss: 126.16715240478516
Iteration 72 Loss: 124.0313949584961
Iteration 73 Loss: 122.78724670410156
Iteration 74 Loss: 126.46257781982422
Iteration 75 Loss: 126.6392593383789
Iteration 76 Loss: 124.64310455322266
Iteration 77 Loss: 124.095703125
Iteration 78 Loss: 125.75817108154297
Iteration 79 Loss: 126.36233520507812
Iteration 80 Loss: 127.07816314697266
Iteration 81 Loss: 123.59893798828125
Iteration 82 Loss: 128.4404754638672
Iteration 83 Loss: 124.2679672241211
Iteration 84 Loss: 124.91661834716797
Iteration 85 Loss: 120.02372741699219
Iteration 86 Loss: 124.01915740966797
Iteration 87 Loss: 128.11758422851562
Iteration 88 Loss: 126.61319732666016
Iteration 89 Loss: 123.83307647705078
Iteration 90 Loss: 124.30843353271484
Iteration 91 Loss: 124.63465118408203
Iteration 92 Loss: 125.04511260986328
Iteration 93 Loss: 125.78772735595703
Iteration 94 Loss: 120.02737426757812
Iteration 95 Loss: 120.34326171875
Iteration 96 Loss: 122.97613525390625
Iteration 97 Loss: 122.7751693725586
Iteration 98 Loss: 120.57945251464844
Iteration 99 Loss: 124.42695617675781
Iteration 100 Loss: 121.80891418457031
Training Complete
Now Testing:charliehebdo-all-rnr-threads.txt

Report for Rumour classification:-
charliehebdo-all-rnr-threads.txt accuracy:0.7326980942828486
charliehebdo-all-rnr-threads.txt macro_f1:0.6231747784276831
charliehebdo-all-rnr-threads.txt total tested:1994

Report for Stance classification:-
correctly classified Stance labels:508
Total available Stance labels:1065
charliehebdo-all-rnr-threads.txt accuracy_stance:0.47699530516431926
charliehebdo-all-rnr-threads.txt macro_stance_f1:0.32829775111560855

Training Set:{'ottawashooting-all-rnr-threads.txt', 'prince-toronto-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 197.89698791503906
Iteration 2 Loss: 199.126220703125
Iteration 3 Loss: 191.3384246826172
Iteration 4 Loss: 195.22903442382812
Iteration 5 Loss: 194.18289184570312
Iteration 6 Loss: 197.76644897460938
Iteration 7 Loss: 197.78643798828125
Iteration 8 Loss: 198.08103942871094
Iteration 9 Loss: 196.21629333496094
Iteration 10 Loss: 195.913818359375
Iteration 11 Loss: 195.3610076904297
Iteration 12 Loss: 193.09597778320312
Iteration 13 Loss: 196.26722717285156
Iteration 14 Loss: 194.96356201171875
Iteration 15 Loss: 196.36985778808594
Iteration 16 Loss: 190.87423706054688
Iteration 17 Loss: 188.80455017089844
Iteration 18 Loss: 195.8772735595703
Iteration 19 Loss: 199.35382080078125
Iteration 20 Loss: 198.55130004882812
Iteration 21 Loss: 194.5050811767578
Iteration 22 Loss: 195.64236450195312
Iteration 23 Loss: 193.84825134277344
Iteration 24 Loss: 185.6800537109375
Iteration 25 Loss: 194.11293029785156
Iteration 26 Loss: 190.8928680419922
Iteration 27 Loss: 186.84007263183594
Iteration 28 Loss: 189.34722900390625
Iteration 29 Loss: 192.04559326171875
Iteration 30 Loss: 198.04090881347656
Iteration 31 Loss: 191.85699462890625
Iteration 32 Loss: 190.94081115722656
Iteration 33 Loss: 190.45140075683594
Iteration 34 Loss: 192.49066162109375
Iteration 35 Loss: 195.99942016601562
Iteration 36 Loss: 190.8905487060547
Iteration 37 Loss: 196.3456573486328
Iteration 38 Loss: 188.15855407714844
Iteration 39 Loss: 186.8394012451172
Iteration 40 Loss: 192.4918212890625
Iteration 41 Loss: 191.65573120117188
Iteration 42 Loss: 192.38510131835938
Iteration 43 Loss: 186.5897216796875
Iteration 44 Loss: 188.0227508544922
Iteration 45 Loss: 182.35690307617188
Iteration 46 Loss: 186.27365112304688
Iteration 47 Loss: 177.91810607910156
Iteration 48 Loss: 182.2121124267578
Iteration 49 Loss: 180.5433349609375
Iteration 50 Loss: 183.12245178222656
Iteration 51 Loss: 180.90985107421875
Iteration 52 Loss: 184.44717407226562
Iteration 53 Loss: 179.77850341796875
Iteration 54 Loss: 181.32635498046875
Iteration 55 Loss: 186.4844512939453
Iteration 56 Loss: 184.86622619628906
Iteration 57 Loss: 180.72181701660156
Iteration 58 Loss: 176.66458129882812
Iteration 59 Loss: 186.06692504882812
Iteration 60 Loss: 181.3953094482422
Iteration 61 Loss: 179.65875244140625
Iteration 62 Loss: 183.78814697265625
Iteration 63 Loss: 187.837158203125
Iteration 64 Loss: 186.13436889648438
Iteration 65 Loss: 181.56431579589844
Iteration 66 Loss: 183.15000915527344
Iteration 67 Loss: 184.1356658935547
Iteration 68 Loss: 183.37973022460938
Iteration 69 Loss: 185.5524139404297
Iteration 70 Loss: 180.1578826904297
Iteration 71 Loss: 181.93313598632812
Iteration 72 Loss: 180.27783203125
Iteration 73 Loss: 180.35433959960938
Iteration 74 Loss: 174.96127319335938
Iteration 75 Loss: 184.82228088378906
Iteration 76 Loss: 188.7406768798828
Iteration 77 Loss: 189.5889434814453
Iteration 78 Loss: 188.0321502685547
Iteration 79 Loss: 179.9059600830078
Iteration 80 Loss: 177.25070190429688
Iteration 81 Loss: 183.42291259765625
Iteration 82 Loss: 182.32156372070312
Iteration 83 Loss: 182.8975067138672
Iteration 84 Loss: 179.720947265625
Iteration 85 Loss: 184.32147216796875
Iteration 86 Loss: 180.36428833007812
Iteration 87 Loss: 176.56077575683594
Iteration 88 Loss: 179.4913787841797
Iteration 89 Loss: 174.26821899414062
Iteration 90 Loss: 175.64474487304688
Iteration 91 Loss: 182.3795166015625
Iteration 92 Loss: 178.42518615722656
Iteration 93 Loss: 188.92112731933594
Iteration 94 Loss: 179.72459411621094
Iteration 95 Loss: 177.6043243408203
Iteration 96 Loss: 178.26316833496094
Iteration 97 Loss: 176.004638671875
Iteration 98 Loss: 179.90736389160156
Iteration 99 Loss: 183.2847137451172
Iteration 100 Loss: 179.43222045898438
Training Complete
Now Testing:ebola-essien-all-rnr-threads.txt

Report for Rumour classification:-
ebola-essien-all-rnr-threads.txt accuracy:0.42857142857142855
ebola-essien-all-rnr-threads.txt macro_f1:0.3
ebola-essien-all-rnr-threads.txt total tested:14

Report for Stance classification:-
correctly classified Stance labels:9
Total available Stance labels:32
ebola-essien-all-rnr-threads.txt accuracy_stance:0.28125
ebola-essien-all-rnr-threads.txt macro_stance_f1:0.15

Training Set:{'ottawashooting-all-rnr-threads.txt', 'prince-toronto-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt'}
Iteration 1 Loss: 179.1643829345703
Iteration 2 Loss: 181.81753540039062
Iteration 3 Loss: 178.9445037841797
Iteration 4 Loss: 180.0626678466797
Iteration 5 Loss: 180.14244079589844
Iteration 6 Loss: 179.48892211914062
Iteration 7 Loss: 182.70448303222656
Iteration 8 Loss: 176.0480499267578
Iteration 9 Loss: 181.39930725097656
Iteration 10 Loss: 179.69277954101562
Iteration 11 Loss: 179.5902099609375
Iteration 12 Loss: 178.72702026367188
Iteration 13 Loss: 182.7335968017578
Iteration 14 Loss: 177.1950225830078
Iteration 15 Loss: 171.5032196044922
Iteration 16 Loss: 176.78135681152344
Iteration 17 Loss: 181.6305694580078
Iteration 18 Loss: 172.81678771972656
Iteration 19 Loss: 171.70217895507812
Iteration 20 Loss: 174.55303955078125
Iteration 21 Loss: 170.4621124267578
Iteration 22 Loss: 170.33953857421875
Iteration 23 Loss: 177.846435546875
Iteration 24 Loss: 182.96388244628906
Iteration 25 Loss: 174.0312957763672
Iteration 26 Loss: 182.13552856445312
Iteration 27 Loss: 171.07424926757812
Iteration 28 Loss: 174.64166259765625
Iteration 29 Loss: 169.4900665283203
Iteration 30 Loss: 173.3997802734375
Iteration 31 Loss: 159.97837829589844
Iteration 32 Loss: 169.85638427734375
Iteration 33 Loss: 171.09097290039062
Iteration 34 Loss: 174.42291259765625
Iteration 35 Loss: 172.6173858642578
Iteration 36 Loss: 173.2760467529297
Iteration 37 Loss: 172.13600158691406
Iteration 38 Loss: 170.95306396484375
Iteration 39 Loss: 168.3167724609375
Iteration 40 Loss: 168.4526824951172
Iteration 41 Loss: 166.0507354736328
Iteration 42 Loss: 171.53326416015625
Iteration 43 Loss: 175.8045196533203
Iteration 44 Loss: 170.42877197265625
Iteration 45 Loss: 165.66256713867188
Iteration 46 Loss: 169.88629150390625
Iteration 47 Loss: 172.1421356201172
Iteration 48 Loss: 170.69529724121094
Iteration 49 Loss: 174.60472106933594
Iteration 50 Loss: 168.26376342773438
Iteration 51 Loss: 171.38108825683594
Iteration 52 Loss: 166.4228057861328
Iteration 53 Loss: 168.7912139892578
Iteration 54 Loss: 172.82040405273438
Iteration 55 Loss: 170.08201599121094
Iteration 56 Loss: 165.55691528320312
Iteration 57 Loss: 168.6433563232422
Iteration 58 Loss: 170.613525390625
Iteration 59 Loss: 171.24929809570312
Iteration 60 Loss: 168.2106170654297
Iteration 61 Loss: 169.41310119628906
Iteration 62 Loss: 164.43597412109375
Iteration 63 Loss: 163.86083984375
Iteration 64 Loss: 173.81605529785156
Iteration 65 Loss: 168.13584899902344
Iteration 66 Loss: 170.77322387695312
Iteration 67 Loss: 163.1717529296875
Iteration 68 Loss: 171.81532287597656
Iteration 69 Loss: 172.74510192871094
Iteration 70 Loss: 169.4057159423828
Iteration 71 Loss: 171.00543212890625
Iteration 72 Loss: 167.3818817138672
Iteration 73 Loss: 169.1939697265625
Iteration 74 Loss: 167.2398223876953
Iteration 75 Loss: 167.35031127929688
Iteration 76 Loss: 170.56492614746094
Iteration 77 Loss: 168.42352294921875
Iteration 78 Loss: 164.935302734375
Iteration 79 Loss: 168.0573272705078
Iteration 80 Loss: 170.93838500976562
Iteration 81 Loss: 168.7514190673828
Iteration 82 Loss: 166.92295837402344
Iteration 83 Loss: 171.32855224609375
Iteration 84 Loss: 168.95126342773438
Iteration 85 Loss: 169.15553283691406
Iteration 86 Loss: 166.0811004638672
Iteration 87 Loss: 166.5948944091797
Iteration 88 Loss: 163.92343139648438
Iteration 89 Loss: 168.08570861816406
Iteration 90 Loss: 167.5759735107422
Iteration 91 Loss: 160.5613555908203
Iteration 92 Loss: 160.02256774902344
Iteration 93 Loss: 166.72946166992188
Iteration 94 Loss: 164.52345275878906
Iteration 95 Loss: 166.27098083496094
Iteration 96 Loss: 164.2893524169922
Iteration 97 Loss: 164.89634704589844
Iteration 98 Loss: 160.46409606933594
Iteration 99 Loss: 169.03231811523438
Iteration 100 Loss: 162.98568725585938
Training Complete
Now Testing:germanwings-crash-all-rnr-threads.txt

Report for Rumour classification:-
germanwings-crash-all-rnr-threads.txt accuracy:0.5136476426799007
germanwings-crash-all-rnr-threads.txt macro_f1:0.5050877192982457
germanwings-crash-all-rnr-threads.txt total tested:403

Report for Stance classification:-
correctly classified Stance labels:187
Total available Stance labels:337
germanwings-crash-all-rnr-threads.txt accuracy_stance:0.5548961424332344
germanwings-crash-all-rnr-threads.txt macro_stance_f1:0.32098474863490867

Training Set:{'ottawashooting-all-rnr-threads.txt', 'prince-toronto-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 155.6846466064453
Iteration 2 Loss: 161.25839233398438
Iteration 3 Loss: 153.88145446777344
Iteration 4 Loss: 152.4562530517578
Iteration 5 Loss: 153.14695739746094
Iteration 6 Loss: 156.2498016357422
Iteration 7 Loss: 154.93251037597656
Iteration 8 Loss: 158.70730590820312
Iteration 9 Loss: 148.7238006591797
Iteration 10 Loss: 147.86203002929688
Iteration 11 Loss: 150.75253295898438
Iteration 12 Loss: 155.23423767089844
Iteration 13 Loss: 147.42025756835938
Iteration 14 Loss: 148.6262664794922
Iteration 15 Loss: 146.50547790527344
Iteration 16 Loss: 150.4899139404297
Iteration 17 Loss: 152.17845153808594
Iteration 18 Loss: 148.6581573486328
Iteration 19 Loss: 144.75148010253906
Iteration 20 Loss: 148.70663452148438
Iteration 21 Loss: 147.86598205566406
Iteration 22 Loss: 152.34730529785156
Iteration 23 Loss: 146.8519744873047
Iteration 24 Loss: 153.02435302734375
Iteration 25 Loss: 146.57363891601562
Iteration 26 Loss: 142.1968231201172
Iteration 27 Loss: 145.38909912109375
Iteration 28 Loss: 149.70538330078125
Iteration 29 Loss: 146.08689880371094
Iteration 30 Loss: 141.00619506835938
Iteration 31 Loss: 141.7379913330078
Iteration 32 Loss: 144.45462036132812
Iteration 33 Loss: 140.51388549804688
Iteration 34 Loss: 149.98834228515625
Iteration 35 Loss: 148.67941284179688
Iteration 36 Loss: 149.7902069091797
Iteration 37 Loss: 154.77960205078125
Iteration 38 Loss: 147.7635040283203
Iteration 39 Loss: 141.70718383789062
Iteration 40 Loss: 144.21095275878906
Iteration 41 Loss: 145.4488983154297
Iteration 42 Loss: 144.3660888671875
Iteration 43 Loss: 142.6337890625
Iteration 44 Loss: 139.58839416503906
Iteration 45 Loss: 145.45079040527344
Iteration 46 Loss: 142.87025451660156
Iteration 47 Loss: 143.956787109375
Iteration 48 Loss: 151.34970092773438
Iteration 49 Loss: 145.5787353515625
Iteration 50 Loss: 147.18429565429688
Iteration 51 Loss: 147.4888153076172
Iteration 52 Loss: 140.16473388671875
Iteration 53 Loss: 143.46897888183594
Iteration 54 Loss: 145.77008056640625
Iteration 55 Loss: 141.3346405029297
Iteration 56 Loss: 141.8529052734375
Iteration 57 Loss: 137.33078002929688
Iteration 58 Loss: 143.26638793945312
Iteration 59 Loss: 141.60240173339844
Iteration 60 Loss: 139.8562774658203
Iteration 61 Loss: 143.7936248779297
Iteration 62 Loss: 147.41001892089844
Iteration 63 Loss: 145.214599609375
Iteration 64 Loss: 143.09471130371094
Iteration 65 Loss: 147.83717346191406
Iteration 66 Loss: 152.74771118164062
Iteration 67 Loss: 145.57479858398438
Iteration 68 Loss: 145.31370544433594
Iteration 69 Loss: 146.53582763671875
Iteration 70 Loss: 151.72525024414062
Iteration 71 Loss: 145.34585571289062
Iteration 72 Loss: 144.82278442382812
Iteration 73 Loss: 142.24075317382812
Iteration 74 Loss: 136.74874877929688
Iteration 75 Loss: 139.91612243652344
Iteration 76 Loss: 141.98439025878906
Iteration 77 Loss: 144.9968719482422
Iteration 78 Loss: 140.55404663085938
Iteration 79 Loss: 134.71180725097656
Iteration 80 Loss: 142.9281005859375
Iteration 81 Loss: 145.38917541503906
Iteration 82 Loss: 143.76943969726562
Iteration 83 Loss: 140.929931640625
Iteration 84 Loss: 137.09622192382812
Iteration 85 Loss: 139.42245483398438
Iteration 86 Loss: 141.5259246826172
Iteration 87 Loss: 140.4498748779297
Iteration 88 Loss: 149.80789184570312
Iteration 89 Loss: 141.87387084960938
Iteration 90 Loss: 142.62826538085938
Iteration 91 Loss: 138.74827575683594
Iteration 92 Loss: 142.42050170898438
Iteration 93 Loss: 142.47378540039062
Iteration 94 Loss: 140.26272583007812
Iteration 95 Loss: 142.87387084960938
Iteration 96 Loss: 144.63470458984375
Iteration 97 Loss: 144.70567321777344
Iteration 98 Loss: 138.56637573242188
Iteration 99 Loss: 134.519287109375
Iteration 100 Loss: 143.02684020996094
Training Complete
Now Testing:sydneysiege-all-rnr-threads.txt

Report for Rumour classification:-
sydneysiege-all-rnr-threads.txt accuracy:0.6085470085470085
sydneysiege-all-rnr-threads.txt macro_f1:0.5676107480029049
sydneysiege-all-rnr-threads.txt total tested:1170

Report for Stance classification:-
correctly classified Stance labels:397
Total available Stance labels:1110
sydneysiege-all-rnr-threads.txt accuracy_stance:0.35765765765765767
sydneysiege-all-rnr-threads.txt macro_stance_f1:0.28200798150372486

Training Set:{'ottawashooting-all-rnr-threads.txt', 'prince-toronto-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 194.24365234375
Iteration 2 Loss: 193.26296997070312
Iteration 3 Loss: 196.46542358398438
Iteration 4 Loss: 197.53929138183594
Iteration 5 Loss: 197.65274047851562
Iteration 6 Loss: 191.03045654296875
Iteration 7 Loss: 192.8861846923828
Iteration 8 Loss: 197.47955322265625
Iteration 9 Loss: 196.92431640625
Iteration 10 Loss: 190.5247802734375
Iteration 11 Loss: 194.13934326171875
Iteration 12 Loss: 190.6548614501953
Iteration 13 Loss: 191.4994354248047
Iteration 14 Loss: 189.3310546875
Iteration 15 Loss: 194.41578674316406
Iteration 16 Loss: 190.81246948242188
Iteration 17 Loss: 200.3335723876953
Iteration 18 Loss: 191.6811065673828
Iteration 19 Loss: 193.9639892578125
Iteration 20 Loss: 192.9837188720703
Iteration 21 Loss: 190.5887908935547
Iteration 22 Loss: 191.6717529296875
Iteration 23 Loss: 186.38613891601562
Iteration 24 Loss: 185.8227081298828
Iteration 25 Loss: 184.10926818847656
Iteration 26 Loss: 189.09339904785156
Iteration 27 Loss: 189.42193603515625
Iteration 28 Loss: 184.16751098632812
Iteration 29 Loss: 181.6046142578125
Iteration 30 Loss: 187.8269500732422
Iteration 31 Loss: 188.1158447265625
Iteration 32 Loss: 181.15554809570312
Iteration 33 Loss: 188.209716796875
Iteration 34 Loss: 188.10952758789062
Iteration 35 Loss: 182.74917602539062
Iteration 36 Loss: 182.41575622558594
Iteration 37 Loss: 182.39263916015625
Iteration 38 Loss: 187.2334747314453
Iteration 39 Loss: 185.63323974609375
Iteration 40 Loss: 179.6051025390625
Iteration 41 Loss: 188.51968383789062
Iteration 42 Loss: 184.4387664794922
Iteration 43 Loss: 188.29075622558594
Iteration 44 Loss: 180.34742736816406
Iteration 45 Loss: 187.3389434814453
Iteration 46 Loss: 181.7700958251953
Iteration 47 Loss: 182.31822204589844
Iteration 48 Loss: 191.42771911621094
Iteration 49 Loss: 178.1387939453125
Iteration 50 Loss: 187.0450439453125
Iteration 51 Loss: 182.11854553222656
Iteration 52 Loss: 186.04254150390625
Iteration 53 Loss: 182.1279754638672
Iteration 54 Loss: 187.44122314453125
Iteration 55 Loss: 184.06956481933594
Iteration 56 Loss: 184.3822021484375
Iteration 57 Loss: 172.95272827148438
Iteration 58 Loss: 186.21136474609375
Iteration 59 Loss: 183.89195251464844
Iteration 60 Loss: 184.32611083984375
Iteration 61 Loss: 181.962646484375
Iteration 62 Loss: 186.03616333007812
Iteration 63 Loss: 185.2213592529297
Iteration 64 Loss: 178.51611328125
Iteration 65 Loss: 183.08990478515625
Iteration 66 Loss: 183.33714294433594
Iteration 67 Loss: 179.79708862304688
Iteration 68 Loss: 182.89779663085938
Iteration 69 Loss: 181.84129333496094
Iteration 70 Loss: 185.1670684814453
Iteration 71 Loss: 172.63699340820312
Iteration 72 Loss: 186.43846130371094
Iteration 73 Loss: 183.48626708984375
Iteration 74 Loss: 180.63734436035156
Iteration 75 Loss: 179.7458038330078
Iteration 76 Loss: 183.6663360595703
Iteration 77 Loss: 178.4732208251953
Iteration 78 Loss: 175.948974609375
Iteration 79 Loss: 181.2991180419922
Iteration 80 Loss: 186.71914672851562
Iteration 81 Loss: 183.24893188476562
Iteration 82 Loss: 180.37632751464844
Iteration 83 Loss: 177.9838409423828
Iteration 84 Loss: 178.44920349121094
Iteration 85 Loss: 177.1820526123047
Iteration 86 Loss: 176.54176330566406
Iteration 87 Loss: 182.67977905273438
Iteration 88 Loss: 180.93118286132812
Iteration 89 Loss: 174.59486389160156
Iteration 90 Loss: 180.87744140625
Iteration 91 Loss: 181.44845581054688
Iteration 92 Loss: 181.5597686767578
Iteration 93 Loss: 176.21958923339844
Iteration 94 Loss: 172.68402099609375
Iteration 95 Loss: 176.97059631347656
Iteration 96 Loss: 181.69557189941406
Iteration 97 Loss: 180.5916290283203
Iteration 98 Loss: 178.61976623535156
Iteration 99 Loss: 181.0862274169922
Iteration 100 Loss: 180.26144409179688
Training Complete
Now Testing:gurlitt-all-rnr-threads.txt

Report for Rumour classification:-
gurlitt-all-rnr-threads.txt accuracy:0.6
gurlitt-all-rnr-threads.txt macro_f1:0.4886363636363637
gurlitt-all-rnr-threads.txt total tested:15

Report for Stance classification:-
correctly classified Stance labels:0
Total available Stance labels:0

Training Set:{'ottawashooting-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 197.69329833984375
Iteration 2 Loss: 189.9940185546875
Iteration 3 Loss: 194.65621948242188
Iteration 4 Loss: 196.5191650390625
Iteration 5 Loss: 191.0766143798828
Iteration 6 Loss: 189.6326141357422
Iteration 7 Loss: 192.86769104003906
Iteration 8 Loss: 186.7381134033203
Iteration 9 Loss: 193.45608520507812
Iteration 10 Loss: 190.58950805664062
Iteration 11 Loss: 181.88528442382812
Iteration 12 Loss: 184.76641845703125
Iteration 13 Loss: 192.995849609375
Iteration 14 Loss: 186.45294189453125
Iteration 15 Loss: 184.90838623046875
Iteration 16 Loss: 187.275390625
Iteration 17 Loss: 184.8675994873047
Iteration 18 Loss: 193.6524658203125
Iteration 19 Loss: 189.07781982421875
Iteration 20 Loss: 181.8828125
Iteration 21 Loss: 181.3271942138672
Iteration 22 Loss: 183.5697021484375
Iteration 23 Loss: 179.84213256835938
Iteration 24 Loss: 176.1261749267578
Iteration 25 Loss: 181.72161865234375
Iteration 26 Loss: 181.37335205078125
Iteration 27 Loss: 181.64816284179688
Iteration 28 Loss: 180.76971435546875
Iteration 29 Loss: 179.57969665527344
Iteration 30 Loss: 182.4015350341797
Iteration 31 Loss: 176.25938415527344
Iteration 32 Loss: 181.03819274902344
Iteration 33 Loss: 180.3451690673828
Iteration 34 Loss: 175.70169067382812
Iteration 35 Loss: 175.08335876464844
Iteration 36 Loss: 178.48907470703125
Iteration 37 Loss: 183.01341247558594
Iteration 38 Loss: 181.93569946289062
Iteration 39 Loss: 180.55918884277344
Iteration 40 Loss: 181.5496826171875
Iteration 41 Loss: 180.73614501953125
Iteration 42 Loss: 182.81863403320312
Iteration 43 Loss: 175.5802764892578
Iteration 44 Loss: 172.52490234375
Iteration 45 Loss: 184.36886596679688
Iteration 46 Loss: 178.5371551513672
Iteration 47 Loss: 179.84580993652344
Iteration 48 Loss: 180.01614379882812
Iteration 49 Loss: 175.1044158935547
Iteration 50 Loss: 173.99472045898438
Iteration 51 Loss: 176.5561065673828
Iteration 52 Loss: 173.205322265625
Iteration 53 Loss: 181.21670532226562
Iteration 54 Loss: 178.45851135253906
Iteration 55 Loss: 176.02816772460938
Iteration 56 Loss: 177.85220336914062
Iteration 57 Loss: 178.55096435546875
Iteration 58 Loss: 176.9031219482422
Iteration 59 Loss: 176.2896728515625
Iteration 60 Loss: 174.85702514648438
Iteration 61 Loss: 177.07485961914062
Iteration 62 Loss: 174.52650451660156
Iteration 63 Loss: 174.44593811035156
Iteration 64 Loss: 180.30419921875
Iteration 65 Loss: 176.30914306640625
Iteration 66 Loss: 178.92599487304688
Iteration 67 Loss: 177.61480712890625
Iteration 68 Loss: 181.91500854492188
Iteration 69 Loss: 180.53302001953125
Iteration 70 Loss: 176.19161987304688
Iteration 71 Loss: 177.96652221679688
Iteration 72 Loss: 171.37567138671875
Iteration 73 Loss: 179.39508056640625
Iteration 74 Loss: 176.54051208496094
Iteration 75 Loss: 184.6593475341797
Iteration 76 Loss: 171.56884765625
Iteration 77 Loss: 181.5425567626953
Iteration 78 Loss: 175.73074340820312
Iteration 79 Loss: 178.99069213867188
Iteration 80 Loss: 174.1855010986328
Iteration 81 Loss: 181.9248046875
Iteration 82 Loss: 175.8647918701172
Iteration 83 Loss: 175.7224884033203
Iteration 84 Loss: 179.6682891845703
Iteration 85 Loss: 175.94375610351562
Iteration 86 Loss: 169.40211486816406
Iteration 87 Loss: 173.27154541015625
Iteration 88 Loss: 173.3218536376953
Iteration 89 Loss: 180.76760864257812
Iteration 90 Loss: 176.78564453125
Iteration 91 Loss: 177.28616333007812
Iteration 92 Loss: 174.9445343017578
Iteration 93 Loss: 174.86602783203125
Iteration 94 Loss: 177.21730041503906
Iteration 95 Loss: 171.0384063720703
Iteration 96 Loss: 178.72308349609375
Iteration 97 Loss: 176.562744140625
Iteration 98 Loss: 173.60394287109375
Iteration 99 Loss: 169.9438018798828
Iteration 100 Loss: 175.483642578125
Training Complete
Now Testing:prince-toronto-all-rnr-threads.txt

Report for Rumour classification:-
prince-toronto-all-rnr-threads.txt accuracy:0.2631578947368421
prince-toronto-all-rnr-threads.txt macro_f1:0.22082735533237685
prince-toronto-all-rnr-threads.txt total tested:133

Report for Stance classification:-
correctly classified Stance labels:46
Total available Stance labels:91
prince-toronto-all-rnr-threads.txt accuracy_stance:0.5054945054945055
prince-toronto-all-rnr-threads.txt macro_stance_f1:0.3565759637188209

Training Set:{'prince-toronto-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 166.00689697265625
Iteration 2 Loss: 169.85186767578125
Iteration 3 Loss: 168.4071044921875
Iteration 4 Loss: 166.60635375976562
Iteration 5 Loss: 164.74729919433594
Iteration 6 Loss: 165.65309143066406
Iteration 7 Loss: 169.5762939453125
Iteration 8 Loss: 165.95599365234375
Iteration 9 Loss: 167.1749267578125
Iteration 10 Loss: 162.62437438964844
Iteration 11 Loss: 163.28594970703125
Iteration 12 Loss: 160.60740661621094
Iteration 13 Loss: 164.1219482421875
Iteration 14 Loss: 165.2061767578125
Iteration 15 Loss: 160.35247802734375
Iteration 16 Loss: 159.9501190185547
Iteration 17 Loss: 158.64268493652344
Iteration 18 Loss: 159.83985900878906
Iteration 19 Loss: 159.89488220214844
Iteration 20 Loss: 159.50926208496094
Iteration 21 Loss: 154.57464599609375
Iteration 22 Loss: 154.85572814941406
Iteration 23 Loss: 158.3725128173828
Iteration 24 Loss: 152.44393920898438
Iteration 25 Loss: 156.8080596923828
Iteration 26 Loss: 153.5198211669922
Iteration 27 Loss: 154.937744140625
Iteration 28 Loss: 157.97940063476562
Iteration 29 Loss: 152.3289337158203
Iteration 30 Loss: 158.63377380371094
Iteration 31 Loss: 160.06178283691406
Iteration 32 Loss: 156.3602294921875
Iteration 33 Loss: 158.76927185058594
Iteration 34 Loss: 157.26919555664062
Iteration 35 Loss: 157.257568359375
Iteration 36 Loss: 157.88490295410156
Iteration 37 Loss: 159.45594787597656
Iteration 38 Loss: 157.64669799804688
Iteration 39 Loss: 154.64523315429688
Iteration 40 Loss: 157.42010498046875
Iteration 41 Loss: 149.03700256347656
Iteration 42 Loss: 157.4005889892578
Iteration 43 Loss: 153.7385711669922
Iteration 44 Loss: 150.45970153808594
Iteration 45 Loss: 147.0760955810547
Iteration 46 Loss: 155.21812438964844
Iteration 47 Loss: 156.32762145996094
Iteration 48 Loss: 160.9670867919922
Iteration 49 Loss: 156.89019775390625
Iteration 50 Loss: 154.5741424560547
Iteration 51 Loss: 156.1552276611328
Iteration 52 Loss: 156.4585723876953
Iteration 53 Loss: 149.69943237304688
Iteration 54 Loss: 148.9626007080078
Iteration 55 Loss: 155.08580017089844
Iteration 56 Loss: 155.2000274658203
Iteration 57 Loss: 153.3671112060547
Iteration 58 Loss: 158.56539916992188
Iteration 59 Loss: 154.4196319580078
Iteration 60 Loss: 159.20167541503906
Iteration 61 Loss: 159.4246826171875
Iteration 62 Loss: 149.86724853515625
Iteration 63 Loss: 152.93186950683594
Iteration 64 Loss: 148.181640625
Iteration 65 Loss: 148.86790466308594
Iteration 66 Loss: 150.25399780273438
Iteration 67 Loss: 152.42820739746094
Iteration 68 Loss: 152.64659118652344
Iteration 69 Loss: 157.77716064453125
Iteration 70 Loss: 150.60789489746094
Iteration 71 Loss: 152.49578857421875
Iteration 72 Loss: 150.49371337890625
Iteration 73 Loss: 154.3586883544922
Iteration 74 Loss: 153.7808837890625
Iteration 75 Loss: 151.63265991210938
Iteration 76 Loss: 156.6901092529297
Iteration 77 Loss: 154.65908813476562
Iteration 78 Loss: 150.25596618652344
Iteration 79 Loss: 152.0852813720703
Iteration 80 Loss: 149.6865997314453
Iteration 81 Loss: 154.17672729492188
Iteration 82 Loss: 153.23741149902344
Iteration 83 Loss: 150.0105743408203
Iteration 84 Loss: 150.1143341064453
Iteration 85 Loss: 150.2380828857422
Iteration 86 Loss: 151.2504119873047
Iteration 87 Loss: 150.2443389892578
Iteration 88 Loss: 150.33120727539062
Iteration 89 Loss: 145.46414184570312
Iteration 90 Loss: 147.0181884765625
Iteration 91 Loss: 153.26429748535156
Iteration 92 Loss: 149.9189910888672
Iteration 93 Loss: 150.0229949951172
Iteration 94 Loss: 149.63478088378906
Iteration 95 Loss: 152.41078186035156
Iteration 96 Loss: 151.05615234375
Iteration 97 Loss: 144.87338256835938
Iteration 98 Loss: 151.07388305664062
Iteration 99 Loss: 145.07176208496094
Iteration 100 Loss: 144.25413513183594
Training Complete
Now Testing:ottawashooting-all-rnr-threads.txt

Report for Rumour classification:-
ottawashooting-all-rnr-threads.txt accuracy:0.5152224824355972
ottawashooting-all-rnr-threads.txt macro_f1:0.45104432561345975
ottawashooting-all-rnr-threads.txt total tested:854

Report for Stance classification:-
correctly classified Stance labels:371
Total available Stance labels:827
ottawashooting-all-rnr-threads.txt accuracy_stance:0.4486094316807739
ottawashooting-all-rnr-threads.txt macro_stance_f1:0.3089018522614514

Training Set:{'ottawashooting-all-rnr-threads.txt', 'prince-toronto-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'ferguson-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 193.66053771972656
Iteration 2 Loss: 188.5565948486328
Iteration 3 Loss: 196.72312927246094
Iteration 4 Loss: 190.51773071289062
Iteration 5 Loss: 193.17779541015625
Iteration 6 Loss: 190.34983825683594
Iteration 7 Loss: 191.00706481933594
Iteration 8 Loss: 191.21212768554688
Iteration 9 Loss: 196.61326599121094
Iteration 10 Loss: 190.188720703125
Iteration 11 Loss: 194.81971740722656
Iteration 12 Loss: 187.5440673828125
Iteration 13 Loss: 194.0115203857422
Iteration 14 Loss: 189.7730712890625
Iteration 15 Loss: 190.39332580566406
Iteration 16 Loss: 188.338134765625
Iteration 17 Loss: 182.3721160888672
Iteration 18 Loss: 189.19566345214844
Iteration 19 Loss: 186.48509216308594
Iteration 20 Loss: 184.20191955566406
Iteration 21 Loss: 177.66261291503906
Iteration 22 Loss: 179.40945434570312
Iteration 23 Loss: 184.49771118164062
Iteration 24 Loss: 179.09844970703125
Iteration 25 Loss: 181.36322021484375
Iteration 26 Loss: 182.02674865722656
Iteration 27 Loss: 178.66078186035156
Iteration 28 Loss: 182.412841796875
Iteration 29 Loss: 182.6254425048828
Iteration 30 Loss: 182.87464904785156
Iteration 31 Loss: 179.0553741455078
Iteration 32 Loss: 178.28392028808594
Iteration 33 Loss: 176.53128051757812
Iteration 34 Loss: 184.70437622070312
Iteration 35 Loss: 183.7927703857422
Iteration 36 Loss: 173.140380859375
Iteration 37 Loss: 183.44619750976562
Iteration 38 Loss: 176.724365234375
Iteration 39 Loss: 169.80931091308594
Iteration 40 Loss: 185.3563232421875
Iteration 41 Loss: 177.1349639892578
Iteration 42 Loss: 183.82138061523438
Iteration 43 Loss: 169.9053955078125
Iteration 44 Loss: 183.94752502441406
Iteration 45 Loss: 175.55555725097656
Iteration 46 Loss: 179.7642822265625
Iteration 47 Loss: 175.13865661621094
Iteration 48 Loss: 176.5537109375
Iteration 49 Loss: 179.47364807128906
Iteration 50 Loss: 182.7397918701172
Iteration 51 Loss: 175.2298583984375
Iteration 52 Loss: 172.1150665283203
Iteration 53 Loss: 181.68875122070312
Iteration 54 Loss: 177.26513671875
Iteration 55 Loss: 181.9833526611328
Iteration 56 Loss: 178.50709533691406
Iteration 57 Loss: 175.30743408203125
Iteration 58 Loss: 179.76092529296875
Iteration 59 Loss: 184.18048095703125
Iteration 60 Loss: 180.4113311767578
Iteration 61 Loss: 179.86558532714844
Iteration 62 Loss: 175.8673553466797
Iteration 63 Loss: 186.31175231933594
Iteration 64 Loss: 181.08740234375
Iteration 65 Loss: 178.55059814453125
Iteration 66 Loss: 177.1043243408203
Iteration 67 Loss: 178.4947052001953
Iteration 68 Loss: 178.4199981689453
Iteration 69 Loss: 176.37844848632812
Iteration 70 Loss: 181.25177001953125
Iteration 71 Loss: 175.83738708496094
Iteration 72 Loss: 179.87356567382812
Iteration 73 Loss: 178.1021270751953
Iteration 74 Loss: 175.6378936767578
Iteration 75 Loss: 174.16741943359375
Iteration 76 Loss: 179.5708770751953
Iteration 77 Loss: 181.76724243164062
Iteration 78 Loss: 178.96009826660156
Iteration 79 Loss: 180.48681640625
Iteration 80 Loss: 174.10690307617188
Iteration 81 Loss: 174.47491455078125
Iteration 82 Loss: 171.39218139648438
Iteration 83 Loss: 174.03785705566406
Iteration 84 Loss: 174.52069091796875
Iteration 85 Loss: 178.65077209472656
Iteration 86 Loss: 174.7095489501953
Iteration 87 Loss: 175.0619659423828
Iteration 88 Loss: 175.74557495117188
Iteration 89 Loss: 176.49734497070312
Iteration 90 Loss: 178.8638458251953
Iteration 91 Loss: 176.8494873046875
Iteration 92 Loss: 175.87686157226562
Iteration 93 Loss: 171.89019775390625
Iteration 94 Loss: 175.2262725830078
Iteration 95 Loss: 173.85177612304688
Iteration 96 Loss: 176.1382598876953
Iteration 97 Loss: 177.65562438964844
Iteration 98 Loss: 168.83499145507812
Iteration 99 Loss: 175.98458862304688
Iteration 100 Loss: 177.67648315429688
Training Complete
Now Testing:putinmissing-all-rnr-threads.txt

Report for Rumour classification:-
putinmissing-all-rnr-threads.txt accuracy:0.4444444444444444
putinmissing-all-rnr-threads.txt macro_f1:0.4444444444444445
putinmissing-all-rnr-threads.txt total tested:135

Report for Stance classification:-
correctly classified Stance labels:26
Total available Stance labels:53
putinmissing-all-rnr-threads.txt accuracy_stance:0.49056603773584906
putinmissing-all-rnr-threads.txt macro_stance_f1:0.3554894179894179

Training Set:{'ottawashooting-all-rnr-threads.txt', 'prince-toronto-all-rnr-threads.txt', 'gurlitt-all-rnr-threads.txt', 'putinmissing-all-rnr-threads.txt', 'sydneysiege-all-rnr-threads.txt', 'charliehebdo-all-rnr-threads.txt', 'ebola-essien-all-rnr-threads.txt', 'germanwings-crash-all-rnr-threads.txt'}
Iteration 1 Loss: 161.947021484375
Iteration 2 Loss: 157.27853393554688
Iteration 3 Loss: 164.80014038085938
Iteration 4 Loss: 163.89022827148438
Iteration 5 Loss: 166.3040771484375
Iteration 6 Loss: 162.45388793945312
Iteration 7 Loss: 164.20956420898438
Iteration 8 Loss: 162.01084899902344
Iteration 9 Loss: 156.77734375
Iteration 10 Loss: 155.1040802001953
Iteration 11 Loss: 164.2964324951172
Iteration 12 Loss: 156.4515380859375
Iteration 13 Loss: 159.30360412597656
Iteration 14 Loss: 157.12127685546875
Iteration 15 Loss: 155.75457763671875
Iteration 16 Loss: 158.0480194091797
Iteration 17 Loss: 157.5319061279297
Iteration 18 Loss: 154.4900360107422
Iteration 19 Loss: 156.88934326171875
Iteration 20 Loss: 156.9054718017578
Iteration 21 Loss: 154.05642700195312
Iteration 22 Loss: 158.2476348876953
Iteration 23 Loss: 157.04649353027344
Iteration 24 Loss: 154.83535766601562
Iteration 25 Loss: 162.35882568359375
Iteration 26 Loss: 158.56016540527344
Iteration 27 Loss: 151.78082275390625
Iteration 28 Loss: 151.4745635986328
Iteration 29 Loss: 153.14903259277344
Iteration 30 Loss: 149.59690856933594
Iteration 31 Loss: 154.61001586914062
Iteration 32 Loss: 152.57614135742188
Iteration 33 Loss: 149.3319549560547
Iteration 34 Loss: 157.343994140625
Iteration 35 Loss: 151.44061279296875
Iteration 36 Loss: 146.6195068359375
Iteration 37 Loss: 150.18479919433594
Iteration 38 Loss: 148.7084503173828
Iteration 39 Loss: 153.50567626953125
Iteration 40 Loss: 147.32643127441406
Iteration 41 Loss: 151.42965698242188
Iteration 42 Loss: 153.2535858154297
Iteration 43 Loss: 149.68438720703125
Iteration 44 Loss: 150.13662719726562
Iteration 45 Loss: 148.20008850097656
Iteration 46 Loss: 152.3304443359375
Iteration 47 Loss: 156.449951171875
Iteration 48 Loss: 155.52587890625
Iteration 49 Loss: 151.1942138671875
Iteration 50 Loss: 150.41082763671875
Iteration 51 Loss: 146.28172302246094
Iteration 52 Loss: 150.5502166748047
Iteration 53 Loss: 148.44873046875
Iteration 54 Loss: 148.2612762451172
Iteration 55 Loss: 151.18655395507812
Iteration 56 Loss: 148.86087036132812
Iteration 57 Loss: 146.53445434570312
Iteration 58 Loss: 155.0953826904297
Iteration 59 Loss: 147.41452026367188
Iteration 60 Loss: 149.79783630371094
Iteration 61 Loss: 152.4071502685547
Iteration 62 Loss: 146.0325164794922
Iteration 63 Loss: 153.8392333984375
Iteration 64 Loss: 147.4499053955078
Iteration 65 Loss: 149.0973358154297
Iteration 66 Loss: 151.3284149169922
Iteration 67 Loss: 151.78231811523438
Iteration 68 Loss: 151.08346557617188
Iteration 69 Loss: 148.73025512695312
Iteration 70 Loss: 147.79959106445312
Iteration 71 Loss: 150.25511169433594
Iteration 72 Loss: 144.41769409179688
Iteration 73 Loss: 146.2019805908203
Iteration 74 Loss: 145.8798065185547
Iteration 75 Loss: 153.2030792236328
Iteration 76 Loss: 150.1376190185547
Iteration 77 Loss: 146.69509887695312
Iteration 78 Loss: 147.6627197265625
Iteration 79 Loss: 148.2752227783203
Iteration 80 Loss: 146.6060333251953
Iteration 81 Loss: 146.5097198486328
Iteration 82 Loss: 148.73931884765625
Iteration 83 Loss: 149.12632751464844
Iteration 84 Loss: 145.12998962402344
Iteration 85 Loss: 146.89556884765625
Iteration 86 Loss: 151.1477813720703
Iteration 87 Loss: 145.31497192382812
Iteration 88 Loss: 149.1311492919922
Iteration 89 Loss: 145.08775329589844
Iteration 90 Loss: 150.38670349121094
Iteration 91 Loss: 144.9793701171875
Iteration 92 Loss: 147.46182250976562
Iteration 93 Loss: 146.7734832763672
Iteration 94 Loss: 148.3516845703125
Iteration 95 Loss: 156.03173828125
Iteration 96 Loss: 160.21035766601562
Iteration 97 Loss: 155.3266143798828
Iteration 98 Loss: 152.90838623046875
Iteration 99 Loss: 154.15411376953125
Iteration 100 Loss: 149.3024139404297
Training Complete
Now Testing:ferguson-all-rnr-threads.txt

Report for Rumour classification:-
ferguson-all-rnr-threads.txt accuracy:0.6617063492063492
ferguson-all-rnr-threads.txt macro_f1:0.5471393845971424
ferguson-all-rnr-threads.txt total tested:1008

Report for Stance classification:-
correctly classified Stance labels:397
Total available Stance labels:1092
ferguson-all-rnr-threads.txt accuracy_stance:0.36355311355311354
ferguson-all-rnr-threads.txt macro_stance_f1:0.21077039776416323

